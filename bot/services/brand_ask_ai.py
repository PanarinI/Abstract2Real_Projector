import os
import logging
from dotenv import load_dotenv
from openai import OpenAI
from bot import config
import re

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–ª—é—á–µ–π API –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
API_KEY = os.getenv("API_KEY")
BASE_URL = os.getenv("BASE_URL")

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=API_KEY, base_url=BASE_URL)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ AI
def ask_ai(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model=config.MODEL_BRAND,
            messages=[
                {"role": "system", "content": "–¢—ã - —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤. "},
                {"role": "user", "content": prompt}
            ],
            max_tokens=config.MAX_TOKENS_BRAND,
            temperature=config.TEMPERATURE_BRAND,
        )
        return response.choices[0].message.content
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI: {e}")
        return ""


# –ü–∞—Ä—Å–µ—Ä –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI
import re
import logging

def parse_ai_response(response: str) -> dict:
    parsed_data = {
        "answer": "",
        "options": []
    }

    if not response or not response.strip():
        logging.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç AI –ø–µ—Ä–µ–¥–∞–Ω –≤ –ø–∞—Ä—Å–µ—Ä!")
        return parsed_data

    lines = response.strip().split('\n')

    def clean_text(text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Å—ã–ª–∫–∏ –∏ HTML."""
        text = re.sub(r'(\*\*|__|[*_~`])', '', text)  # –£–±–∏—Ä–∞–µ–º –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –∫—É—Ä—Å–∏–≤
        text = re.sub(r'\s+', ' ', text)  # –°–∂–∏–º–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
        return text.strip()

    def convert_markdown_links(text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Markdown-—Å—Å—ã–ª–∫–∏ [—Ç–µ–∫—Å—Ç](URL) –≤ HTML <a href="URL">—Ç–µ–∫—Å—Ç</a>"""
        return re.sub(r'\[([^\]]+)\]\((https?://[^\)]+)\)', r'<a href="\2">\1</a>', text)

    for line in lines:
        line = clean_text(line.strip())
        if not line:
            continue

        # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è (–µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
        if not parsed_data["answer"]:
            if "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:" in line:
                parsed_data["answer"] = convert_markdown_links(line.split("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:", 1)[1].strip())
            else:
                parsed_data["answer"] = convert_markdown_links(line.strip())
            continue

        # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å —Ü–∏—Ñ—Ä—ã –∏ —Ç–æ—á–∫–∏ –∏–ª–∏ —Å —Å–∏–º–≤–æ–ª–∞ "‚Ä¢"
        if (len(line) > 2 and line[0].isdigit() and line[1] == '.') or line.startswith("‚Ä¢"):
            if line.startswith("‚Ä¢"):
                option_body = line[1:].strip()
            else:
                option_body = line.split('.', 1)[1].strip()

            # üíÄ –û–ü–ê–°–ù–´–ô –ú–û–ú–ï–ù–¢: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤
            separator_match = re.search(r'\s*[:\-‚Äî‚Äì|/\\>]\s+(?!\S*[-:]\S*)', option_body)

            if separator_match:
                separator = separator_match.group()
                left_part, details = option_body.split(separator, 1)
                left_part = left_part.strip()
                details = convert_markdown_links(details.strip())
            else:
                # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–ª—É—á–∞–π —Å —ç–º–æ–¥–∑–∏ + –∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç
                match = re.match(r'^(.*?)\s*\*\*(.*?)\*\*\s*:\s*(.*)$', option_body)
                if match:
                    emoji, short_text, details = match.groups()
                    left_part = f"{emoji} {short_text}".strip()
                    details = convert_markdown_links(details.strip())
                else:
                    parts = option_body.split()
                    left_part = parts[0] if parts else option_body
                    details = convert_markdown_links(" ".join(parts[1:]) if len(parts) > 1 else "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è.")
            parsed_data["options"].append({
                "short": left_part,  # –ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –≤–∫–ª—é—á–∞—è –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                "full": f"<b>{left_part}</b>: {details}"  # –ü–æ–ª–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Å HTML-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            })

    # –ï—Å–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω, –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
    if not parsed_data["answer"] and lines:
        parsed_data["answer"] = convert_markdown_links(clean_text(lines[0].strip()))

    if not parsed_data["options"]:
        logging.error("‚ùå –ü–∞—Ä—Å–µ—Ä –Ω–µ –Ω–∞—à–µ–ª 'options' –≤ –æ—Ç–≤–µ—Ç–µ AI!")
        parsed_data["options"] = [{
            "short": "–û—à–∏–±–∫–∞",
            "full": "–û—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        }]

    return parsed_data





##

# –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ AI –∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞
def get_parsed_response(prompt: str) -> dict:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ AI, –ª–æ–≥–∏—Ä—É–µ—Ç —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç, –ø–∞—Ä—Å–∏—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
    """
    response = ask_ai(prompt)
    logging.info(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç AI: {response}")

    parsed = parse_ai_response(response)
    logging.info(f"–ü–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {parsed}")

    return parsed
